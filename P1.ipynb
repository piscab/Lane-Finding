{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newly added functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math # required by added functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polygon_from_shape(imshape, delta=0.5, d=25):\n",
    "    \"\"\"\n",
    "    `poligon_from_shape` identifies a symmetric poligon (isosceles trapezoid)\n",
    "    from the bottom of the image \n",
    "    First, you imagine a triangle where:\n",
    "    - the base is at the bottom of the picture, with length imshape[1]\n",
    "    - the heigth \"delta\" is set (by default=0.5) in the middle of the picture\n",
    "      but can be moved at the top (delta=0) \n",
    "      or actually at the bottom (delta=1)\n",
    "    Second, you want to cut a little triangle \n",
    "    at the top of the just made bigger one \n",
    "    - where the length of its heigth is of \"d\" pixels (default d=25)\n",
    "    Once cut, you get your centered polygon\n",
    "      \n",
    "    NOTE: Be careful, current version needs a lot of coherence checks \n",
    "    \"\"\"\n",
    "    import math\n",
    "    \n",
    "    H = imshape[0] # vertical length\n",
    "    B = imshape[1] # horizontal length\n",
    "\n",
    "    # to build a triangle with a vertex in the middle of the picture\n",
    "    h = H * delta\n",
    "    myRatio = float(B) / float(h)\n",
    "\n",
    "    # s, the small half-base of the small tringle \n",
    "    s = int (d * myRatio / 2.)\n",
    "    \n",
    "    # now, you can draw your four sided polygon to mask\n",
    "    vertices = np.array([[(0,H),(B/2-s, h+d), (B/2+s, h+d), (B,H)]], dtype=np.int32)\n",
    "    h_d = h+d\n",
    "    return vertices, h_d\n",
    "\n",
    "def lane_from_lines(img,lines2,h_d,h_max):\n",
    "    \"\"\"\n",
    "    `lane_from_lines` return left and rigth lanes \n",
    "    from red lanes drawn over a black picture (lanes2).\n",
    "    Also, it needs \"h_d\" the heigth of the trapezoid\n",
    "    and \"h_max\" the total height of the picture.(see the \"polygon_from_shape\" function) \n",
    "      \n",
    "    NOTE: Be careful, current version needs a coherent polygon_from_shape function \n",
    "     \n",
    "    \"\"\"\n",
    "    #creating a blank to draw lines on\n",
    "    line_image = np.copy(img)*0 \n",
    "\n",
    "    # Extract point\n",
    "    x1=np.reshape(np.hstack(lines2),[len(lines2),4])[:,0]\n",
    "    y1=np.reshape(np.hstack(lines2),[len(lines2),4])[:,1]\n",
    "    x2=np.reshape(np.hstack(lines2),[len(lines2),4])[:,2]\n",
    "    y2=np.reshape(np.hstack(lines2),[len(lines2),4])[:,3]\n",
    "    \n",
    "    # y = mx + q\n",
    "    # NOTE: henceforth we work with y axis rolled up-down (x is ok)\n",
    "    \n",
    "    # Check for vertical lines\n",
    "    m_inf = (x2-x1) == 0\n",
    "\n",
    "    # Check for horizontal lines\n",
    "    # m_0 = (y2-y1) == 0\n",
    "    \n",
    "    # set m and q to 0.\n",
    "    m = x1 * 0.\n",
    "    q = y1 * 0.\n",
    "\n",
    "    # m and q will assume a decent value or stay zero\n",
    "    m[~m_inf] = (y2[~m_inf] - y1[~m_inf]) / (x2[~m_inf] - x1[~m_inf])    \n",
    "    q[~m_inf] =  y2[~m_inf] -  m[~m_inf]  *  x2[~m_inf] \n",
    "    \n",
    "    top_x    = x1 * 0. # if rare and still 0 median should exclude it\n",
    "    bottom_x = x1 * 0. # if rare and still 0 median should exclude it\n",
    "    top_x[~m_inf]    = (h_d   - q[~m_inf]) / m[~m_inf]\n",
    "    bottom_x[~m_inf] = (h_max - q[~m_inf]) / m[~m_inf]\n",
    "        \n",
    "    rigth = m > 0 # the image is rolled up-down!\n",
    "        \n",
    "    # Draw left line\n",
    "    x1 = int(np.median(bottom_x[~rigth])+0.5) # median is more robust than any mean\n",
    "    y1 = int(h_max)\n",
    "    x2 = int(np.median(top_x   [~rigth])+0.5)\n",
    "    y2 = int(h_d)\n",
    "    cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "    \n",
    "    # Draw rigth line\n",
    "    x1 = int(np.median(bottom_x[rigth])+0.5)\n",
    "    y1 = int(h_max)\n",
    "    x2 = int(np.median(top_x   [rigth])+0.5)\n",
    "    y2 = int(h_d)\n",
    "    cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "    \n",
    "    return line_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "my_image_list = os.listdir(\"input/test_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_pipeline(image, display=False):\n",
    "    \"\"\"\n",
    "    `image_pipeline` is the mainstream program for testing \n",
    "    lines detection on single images\n",
    "    \n",
    "    \"image\" will be / must be a picture \n",
    "    \n",
    "    For displaying (all) intermediate images, set \"display\" to True\n",
    "    \n",
    "    This function could be improved:\n",
    "    - automating \"triangle cut\" dimension \"d\" to have an intelligent trapezoid\n",
    "    - weighting segments (with the length of each segment) when calculating medians \n",
    "    \"\"\"\n",
    "    \n",
    "    if display: \n",
    "        # Print out some stats\n",
    "        print('This image is: ',type(image),'with dimensions:',image.shape)\n",
    "        \n",
    "    # Pull out the x and y sizes and make a copy of the image\n",
    "    ysize = image.shape[0]\n",
    "    # xsize = image.shape[1]\n",
    "    \n",
    "    # Grayscale the image\n",
    "    gray = grayscale(image)\n",
    "    \n",
    "    # Define a kernel size and apply Gaussian smoothing\n",
    "    kernel_size = 5\n",
    "    blur_gray = gaussian_blur(gray, kernel_size)\n",
    "    \n",
    "    # Define parameters for Canny and apply\n",
    "    low_threshold = 80\n",
    "    high_threshold = 200\n",
    "    edges = canny (blur_gray, low_threshold, high_threshold)\n",
    "    \n",
    "    # Define the Hough transform parameters\n",
    "    rho = 1\n",
    "    theta = np.pi/180\n",
    "    threshold = 20 # was 20\n",
    "    min_line_len = 10 #was 10 \n",
    "    max_line_gap = 20 # was 16\n",
    "    \n",
    "    # Run Hough on edge detected image\n",
    "    line_img = hough_lines(edges, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "\n",
    "    # Define four sided polygon to mask\n",
    "    vertices,h_d = polygon_from_shape(line_img.shape, delta=0.5, d=60)\n",
    "    \n",
    "    # Apply the image mask.\n",
    "    masked_edges = region_of_interest(line_img, vertices)\n",
    "    \n",
    "    # Redo Canny & Hough on the selected line_img\n",
    "    edges2 = canny (masked_edges, low_threshold, high_threshold)\n",
    "    lines2 = cv2.HoughLinesP(edges2, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap) \n",
    "    \n",
    "    # Find the two lines (outputs from polygon_from_shape are needed!)\n",
    "    line_image = lane_from_lines(masked_edges,lines2,h_d,ysize)\n",
    "\n",
    "    # Draw the lines on the edge image\n",
    "    combo = cv2.addWeighted(image, 0.8, line_image, 1, 0) \n",
    "    \n",
    "    # Display all the (modified) images       \n",
    "    if display:   \n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.imshow(image);plt.show()\n",
    "        plt.xticks([]), plt.yticks([]);plt.imshow(gray, cmap='gray');plt.show()\n",
    "        plt.xticks([]), plt.yticks([]);plt.imshow(blur_gray, cmap='gray');plt.show()\n",
    "        plt.xticks([]), plt.yticks([]);plt.imshow(edges, cmap='Greys_r');plt.show()\n",
    "        plt.imshow(line_img);plt.show()\n",
    "        plt.imshow(masked_edges);plt.show()\n",
    "        plt.imshow(edges2, cmap='Greys_r');plt.show()\n",
    "        plt.imshow(line_image);plt.show()\n",
    "        plt.xticks([]), plt.yticks([]);plt.imshow(combo);plt.show()\n",
    "        \n",
    "    return combo\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for myImg in my_image_list:\n",
    "    \n",
    "    # Read in the image \n",
    "    file_in = \"\".join([\"input/test_images/\",myImg])\n",
    "    image = mpimg.imread(file_in) \n",
    "    \n",
    "    # Run mainstream program for testing lines detection\n",
    "    result = image_pipeline(image, display=False)\n",
    "    \n",
    "    # Save the result array as image file\n",
    "    file_out = \"_\".join([\"output/my_images/my\",myImg])\n",
    "    mpimg.imsave(file_out,result)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image with lines are drawn on lanes)\n",
    "    result = image_pipeline(image)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the one with the solid white lane on the right first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output/my_video/solidWhiteR.mp4\n",
      "[MoviePy] Writing video output/my_video/solidWhiteR.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:11<00:00, 19.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output/my_video/solidWhiteR.mp4 \n",
      "\n",
      "CPU times: user 10.1 s, sys: 2.22 s, total: 12.4 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'output/my_video/solidWhiteR.mp4'\n",
    "clip1 = VideoFileClip(\"input/test_video/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the one with the solid yellow lane on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output/my_video/solidYellowL.mp4\n",
      "[MoviePy] Writing video output/my_video/solidYellowL.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:39<00:00, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output/my_video/solidYellowL.mp4 \n",
      "\n",
      "CPU times: user 34.3 s, sys: 6.87 s, total: 41.1 s\n",
      "Wall time: 40.8 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'output/my_video/solidYellowL.mp4'\n",
    "clip2 = VideoFileClip('input/test_video/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Line finding is amazing.  \n",
    "\n",
    "In this program, once the line equations have been found via the Hough Lines algorithm, I introduce a \"median way\" to find the extreme point of right and left lane-lines: I think this way is more robust than averaging, in avoiding the influence of possible horizontal/noising lines.\n",
    "\n",
    "I found some trouble in capturing lines on the road, when they are very short: It could happen if you miss any reference on one side (e.g. in the yellow lane example).  \n",
    "For dealing with these cases, I prefer to set min_line_len at a very low level:\n",
    "```  min_line_len = 10 \n",
    "```  \n",
    "\n",
    "This approach requires an accurate line \"selection\" and, with this aim, I run Canny and Hough functions twice. This solution is time-consuming, but I think it is still acceptable for this P1. \n",
    "\n",
    "In a more complex trial, there are few more aspects of working on: \n",
    "* set the mask dimension in an adaptive “intelligent” dimension \n",
    "* slowly increase or modify the value of all parameters (min_line_len included!) \n",
    "* in movies, judging/learning/storing results from past images could lead to more stable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
